{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9bfc675-6baf-4417-a435-2e74fe236711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def welch_variance_spectrum(\n",
    "    eta_m: np.ndarray,\n",
    "    fs: float,\n",
    "    nperseg: int,\n",
    "    noverlap: int,\n",
    "    window: str = \"hann\",\n",
    "    detrend: str = \"constant\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Welch variance spectrum S_etaeta(f) (m^2/Hz), with an approximate DOF and 95% CI.\n",
    "    Returns: f, S, S_lo, S_hi, dof, K\n",
    "    \"\"\"\n",
    "    eta_m = np.asarray(eta_m, dtype=float)\n",
    "    eta_m = eta_m[np.isfinite(eta_m)]\n",
    "    if eta_m.size < nperseg:\n",
    "        raise ValueError(\"Time series shorter than nperseg after removing NaNs.\")\n",
    "\n",
    "    f, S = welch(\n",
    "        eta_m,\n",
    "        fs=fs,\n",
    "        window=window,\n",
    "        nperseg=nperseg,\n",
    "        noverlap=noverlap,\n",
    "        detrend=detrend,\n",
    "        scaling=\"density\",   # -> m^2/Hz if eta in meters\n",
    "        return_onesided=True\n",
    "    )\n",
    "\n",
    "    # Welch segment count (K): scipy doesn't return it, so estimate it.\n",
    "    # With step = nperseg - noverlap, number of segments:\n",
    "    step = nperseg - noverlap\n",
    "    K = 1 + (eta_m.size - nperseg) // step\n",
    "    K = int(max(K, 1))\n",
    "\n",
    "    # Approx DOF for Welch (simple, commonly used approximation)\n",
    "    dof = 2 * K\n",
    "\n",
    "    # 95% confidence limits using chi-square distribution\n",
    "    alpha = 0.05\n",
    "    chi2_lo = chi2.ppf(1 - alpha/2, dof)  # 0.975 quantile\n",
    "    chi2_hi = chi2.ppf(alpha/2, dof)      # 0.025 quantile\n",
    "    S_lo = (dof * S) / chi2_lo\n",
    "    S_hi = (dof * S) / chi2_hi\n",
    "\n",
    "    return f, S, S_lo, S_hi, dof, K\n",
    "\n",
    "\n",
    "def bulk_stats_from_spectrum(f, S, fmin=None, fmax=None):\n",
    "    \"\"\"\n",
    "    Compute m0, Hm0, Tp, Tm0 from variance spectrum S(f).\n",
    "    Optional band limits (fmin/fmax) allow restricting integration range.\n",
    "    \"\"\"\n",
    "    f = np.asarray(f, dtype=float)\n",
    "    S = np.asarray(S, dtype=float)\n",
    "\n",
    "    mask = np.isfinite(f) & np.isfinite(S) & (f > 0)\n",
    "    if fmin is not None:\n",
    "        mask &= (f >= fmin)\n",
    "    if fmax is not None:\n",
    "        mask &= (f <= fmax)\n",
    "\n",
    "    ff = f[mask]\n",
    "    SS = S[mask]\n",
    "    if ff.size < 3:\n",
    "        return dict(m0=np.nan, Hm0=np.nan, fp=np.nan, Tp=np.nan, m1=np.nan, Tm0=np.nan)\n",
    "\n",
    "    m0 = np.trapezoid(SS, ff)\n",
    "    m1 = np.trapezoid(ff * SS, ff)\n",
    "\n",
    "    Hm0 = 4.0 * np.sqrt(m0) if m0 > 0 else np.nan\n",
    "\n",
    "    # Peak period\n",
    "    ipeak = np.argmax(SS)\n",
    "    fp = ff[ipeak]\n",
    "    Tp = 1.0 / fp if fp > 0 else np.nan\n",
    "\n",
    "    # Mean period Tm0 = m0 / m1\n",
    "    Tm0 = (m0 / m1) if (m1 > 0) else np.nan\n",
    "\n",
    "    return dict(m0=m0, Hm0=Hm0, fp=fp, Tp=Tp, m1=m1, Tm0=Tm0)\n",
    "\n",
    "\n",
    "def add_period_axis(ax, period_ticks_s=(0.5, 1, 2, 5, 10, 20, 50)):\n",
    "    \"\"\"\n",
    "    Add a top x-axis labeled Period (s) corresponding to bottom frequency axis (Hz).\n",
    "    Works best for log-scaled frequency axes.\n",
    "    \"\"\"\n",
    "    ax_top = ax.twiny()\n",
    "    ax_top.set_xscale(\"log\")\n",
    "\n",
    "    # Match limits in frequency space\n",
    "    fmin, fmax = ax.get_xlim()\n",
    "    ax_top.set_xlim(fmin, fmax)\n",
    "\n",
    "    # Place ticks at frequencies corresponding to selected periods\n",
    "    period_ticks_s = np.asarray(period_ticks_s, dtype=float)\n",
    "    f_ticks = 1.0 / period_ticks_s\n",
    "\n",
    "    # Keep only ticks within current frequency limits\n",
    "    mask = (f_ticks >= fmin) & (f_ticks <= fmax)\n",
    "    ax_top.set_xticks(f_ticks[mask])\n",
    "    ax_top.set_xticklabels([f\"{p:g}\" for p in period_ticks_s[mask]])\n",
    "\n",
    "    ax_top.set_xlabel(\"Period (s)\")\n",
    "    return ax_top\n",
    "\n",
    "    \n",
    "def analyze_experiment(\n",
    "    site_dfs: dict,\n",
    "    color_map: dict,\n",
    "    experiment_name: str,\n",
    "    fs: float = 8.0,\n",
    "    seg_seconds: float = 120.0,\n",
    "    overlap_frac: float = 0.5,\n",
    "    fmin: float = 0.02,\n",
    "    fmax: float = 2.5,\n",
    "    eta_col: str = \"Waves\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute Welch variance spectra, 95% CI, and bulk wave statistics\n",
    "    for one experiment with multiple sites.\n",
    "    \"\"\"\n",
    "\n",
    "    nperseg = int(seg_seconds * fs)\n",
    "    noverlap = int(overlap_frac * nperseg)\n",
    "\n",
    "    spec = {}\n",
    "    stats_rows = []\n",
    "\n",
    "    for site, df in site_dfs.items():\n",
    "\n",
    "        # ---- Minimal conversion: DataFrame â†’ NumPy ----\n",
    "        eta = df[eta_col].to_numpy(dtype=float)\n",
    "        eta = eta[np.isfinite(eta)]   # optional but safe\n",
    "\n",
    "        # ---- Welch variance spectrum ----\n",
    "        f, S = welch(\n",
    "            eta,\n",
    "            fs=fs,\n",
    "            window=\"hann\",\n",
    "            nperseg=nperseg,\n",
    "            noverlap=noverlap,\n",
    "            detrend=\"constant\",\n",
    "            scaling=\"density\",\n",
    "            return_onesided=True\n",
    "        )\n",
    "\n",
    "        # ---- Welch degrees of freedom (approximate) ----\n",
    "        step = nperseg - noverlap\n",
    "        K = 1 + (len(eta) - nperseg) // step\n",
    "        K = int(max(K, 1))\n",
    "        dof = 2 * K\n",
    "\n",
    "        # ---- 95% confidence limits ----\n",
    "        alpha = 0.05\n",
    "        Slo = (dof * S) / chi2.ppf(1 - alpha / 2, dof)\n",
    "        Shi = (dof * S) / chi2.ppf(alpha / 2, dof)\n",
    "\n",
    "        # ---- Bulk stats ----\n",
    "        mask = (f >= fmin) & (f <= fmax)\n",
    "        ff = f[mask]\n",
    "        SS = S[mask]\n",
    "\n",
    "        m0 = np.trapezoid(SS, ff)\n",
    "        m1 = np.trapezoid(ff * SS, ff)\n",
    "\n",
    "        Hm0 = 4 * np.sqrt(m0)\n",
    "        fp = ff[np.argmax(SS)]\n",
    "        Tp = 1 / fp\n",
    "        Tm0 = m0 / m1\n",
    "\n",
    "        spec[site] = dict(f=f, S=S, Slo=Slo, Shi=Shi, dof=dof, K=K)\n",
    "\n",
    "        stats_rows.append({\n",
    "            \"experiment\": experiment_name,\n",
    "            \"site\": site,\n",
    "            \"Hm0 (m)\": Hm0,\n",
    "            \"Tp (s)\": Tp,\n",
    "            \"Tm0 (s)\": Tm0,\n",
    "            \"segments_K\": K,\n",
    "            \"dof\": dof\n",
    "        })\n",
    "\n",
    "    stats_df = pd.DataFrame(stats_rows)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    for site in site_dfs.keys():   # <-- uses keys in order\n",
    "        print(site)\n",
    "        out = spec[site]\n",
    "        f, S = out[\"f\"], out[\"S\"]\n",
    "        mask = (f >= fmin) & (f <= fmax)\n",
    "    \n",
    "        # ax.loglog(f[mask], S[mask], color=color_map.get(site), label=site)\n",
    "        ax.semilogx(f[mask], S[mask], color=color_map.get(site), label=site)\n",
    "\n",
    "        ax.fill_between(\n",
    "            f[mask],\n",
    "            out[\"Slo\"][mask],\n",
    "            out[\"Shi\"][mask],\n",
    "            alpha=0.25,\n",
    "            linewidth=0,\n",
    "            color=color_map.get(site),\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel(\"Frequency (Hz)\")\n",
    "    ax.set_ylabel(r\"Variance spectrum $S_{\\eta\\eta}(f)$ (m$^2$/Hz)\")\n",
    "    ax.set_title(\n",
    "        f\"{experiment_name}: Welch variance spectra\\n\"\n",
    "        f\"{seg_seconds:.0f}-s segments, {overlap_frac*100:.0f}% overlap\"\n",
    "    )\n",
    "    ax.grid(True, which=\"both\")\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add top axis in Period (s)\n",
    "    add_period_axis(ax, period_ticks_s=(0.5, 1, 2, 5, 10, 20, 50))\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return spec, stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a8990e6-9aa7-4f21-beb1-f98666ba1469",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'users/sophiafamely/Documents/ScienceFair2526/Data/BlueData.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Read processed data\u001b[39;00m\n\u001b[32m      2\u001b[39m data_dir = \u001b[33m\"\u001b[39m\u001b[33musers/sophiafamely/Documents/ScienceFair2526/Data/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m df_blue1r = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m+\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBlueData.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m df_red1r = pd.read_csv( data_dir+\u001b[33m\"\u001b[39m\u001b[33mRedData.txt\u001b[39m\u001b[33m\"\u001b[39m, index_col=\u001b[32m0\u001b[39m, parse_dates=\u001b[38;5;28;01mTrue\u001b[39;00m )\n\u001b[32m      5\u001b[39m df_green1r = pd.read_csv( data_dir+\u001b[33m\"\u001b[39m\u001b[33mGreenData.txt\u001b[39m\u001b[33m\"\u001b[39m, index_col=\u001b[32m0\u001b[39m, parse_dates=\u001b[38;5;28;01mTrue\u001b[39;00m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fa-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fa-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fa-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fa-env/lib/python3.13/site-packages/pandas/io/parsers/readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fa-env/lib/python3.13/site-packages/pandas/io/common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'users/sophiafamely/Documents/ScienceFair2526/Data/BlueData.txt'"
     ]
    }
   ],
   "source": [
    "# Read processed data\n",
    "data_dir = \"users/sophiafamely/Documents/ScienceFair2526/Data/\"\n",
    "df_blue1r = pd.read_csv( data_dir+\"BlueData.txt\", index_col=0, parse_dates=True )\n",
    "df_red1r = pd.read_csv( data_dir+\"RedData.txt\", index_col=0, parse_dates=True )\n",
    "df_green1r = pd.read_csv( data_dir+\"GreenData.txt\", index_col=0, parse_dates=True )\n",
    "\n",
    "df_yellow2r = pd.read_csv( data_dir+\"YellowData.txt\", index_col=0, parse_dates=True )\n",
    "df_red2r = pd.read_csv( data_dir+\"RedData.txt\", index_col=0, parse_dates=True )\n",
    "df_green2r = pd.read_csv( data_dir+\"GreenData.txt\", index_col=0, parse_dates=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db919fe2-9f74-4fd7-a57f-aedb6c472a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process exp. 1\n",
    "exp1_sites = {'Offshore': df_blue1r, 'Rocks': df_red1r, 'Sand': df_yellow1r, 'Grass': df_green1r }\n",
    "color_map1  = {\n",
    "    \"Offshore\": \"b\",       # blue\n",
    "    \"Rocks\":    \"r\",       # red\n",
    "    \"Sand\":     \"gold\",    # yellow\n",
    "    \"Grass\":    \"g\",       # green\n",
    "}\n",
    "spec1, stats1 = analyze_experiment(exp1_sites, color_map1, \"Experiment 1\")\n",
    "print(\"spec keys:\", list(spec1.keys()))\n",
    "print(\"stats rows:\", len(stats1))\n",
    "\n",
    "# Process exp. 2\n",
    "exp2_sites = {'Offshore': df_blue2r, 'Mid': df_red2r, 'Shallow': df_yellow2r, 'Grass': df_green2r }\n",
    "color_map2  = {\n",
    "    \"Offshore\": \"b\",       # blue\n",
    "    \"Mid\":    \"r\",       # red\n",
    "    \"Shallow\":     \"gold\",    # yellow\n",
    "    \"Grass\":    \"g\",       # green\n",
    "}\n",
    "spec2, stats2 = analyze_experiment(exp2_sites, color_map2, \"Experiment 2\")\n",
    "print(\"spec keys:\", list(spec2.keys()))\n",
    "print(\"stats rows:\", len(stats2))\n",
    "\n",
    "# Combine stats tables if desired:\n",
    "stats_all = pd.concat([stats1, stats2], ignore_index=True)\n",
    "display(stats_all)\n",
    "stats_all.to_csv(\"wave_bulk_stats_welch.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0078f327-06c7-4a99-9b5d-f779c7d2ca7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
