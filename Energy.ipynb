{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9bfc675-6baf-4417-a435-2e74fe236711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import chi2\n",
    "\n",
    "# ----------------------------\n",
    "# Helpers\n",
    "# ----------------------------\n",
    "def welch_variance_spectrum(\n",
    "    eta_m: np.ndarray,\n",
    "    fs: float,\n",
    "    nperseg: int,\n",
    "    noverlap: int,\n",
    "    window: str = \"hann\",\n",
    "    detrend: str = \"constant\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Welch variance spectrum S_etaeta(f) (m^2/Hz), with an approximate DOF and 95% CI.\n",
    "    Returns: f, S, S_lo, S_hi, dof, K\n",
    "    \"\"\"\n",
    "    eta_m = np.asarray(eta_m, dtype=float)\n",
    "    eta_m = eta_m[np.isfinite(eta_m)]\n",
    "    if eta_m.size < nperseg:\n",
    "        raise ValueError(\"Time series shorter than nperseg after removing NaNs.\")\n",
    "\n",
    "    f, S = welch(\n",
    "        eta_m,\n",
    "        fs=fs,\n",
    "        window=window,\n",
    "        nperseg=nperseg,\n",
    "        noverlap=noverlap,\n",
    "        detrend=detrend,\n",
    "        scaling=\"density\",   # -> m^2/Hz if eta in meters\n",
    "        return_onesided=True\n",
    "    )\n",
    "\n",
    "    # Welch segment count (K): scipy doesn't return it, so estimate it.\n",
    "    # With step = nperseg - noverlap, number of segments:\n",
    "    step = nperseg - noverlap\n",
    "    K = 1 + (eta_m.size - nperseg) // step\n",
    "    K = int(max(K, 1))\n",
    "\n",
    "    # Approx DOF for Welch (simple, commonly used approximation)\n",
    "    dof = 2 * K\n",
    "\n",
    "    # 95% confidence limits using chi-square distribution\n",
    "    alpha = 0.05\n",
    "    chi2_lo = chi2.ppf(1 - alpha/2, dof)  # 0.975 quantile\n",
    "    chi2_hi = chi2.ppf(alpha/2, dof)      # 0.025 quantile\n",
    "    S_lo = (dof * S) / chi2_lo\n",
    "    S_hi = (dof * S) / chi2_hi\n",
    "\n",
    "    return f, S, S_lo, S_hi, dof, K\n",
    "\n",
    "\n",
    "def bulk_stats_from_spectrum(f, S, fmin=None, fmax=None):\n",
    "    \"\"\"\n",
    "    Compute m0, Hm0, Tp, Tm0 from variance spectrum S(f).\n",
    "    Optional band limits (fmin/fmax) allow restricting integration range.\n",
    "    \"\"\"\n",
    "    f = np.asarray(f, dtype=float)\n",
    "    S = np.asarray(S, dtype=float)\n",
    "\n",
    "    mask = np.isfinite(f) & np.isfinite(S) & (f > 0)\n",
    "    if fmin is not None:\n",
    "        mask &= (f >= fmin)\n",
    "    if fmax is not None:\n",
    "        mask &= (f <= fmax)\n",
    "\n",
    "    ff = f[mask]\n",
    "    SS = S[mask]\n",
    "    if ff.size < 3:\n",
    "        return dict(m0=np.nan, Hm0=np.nan, fp=np.nan, Tp=np.nan, m1=np.nan, Tm0=np.nan)\n",
    "\n",
    "    m0 = np.trapezoid(SS, ff)\n",
    "    m1 = np.trapezoid(ff * SS, ff)\n",
    "\n",
    "    Hm0 = 4.0 * np.sqrt(m0) if m0 > 0 else np.nan\n",
    "\n",
    "    # Peak period\n",
    "    ipeak = np.argmax(SS)\n",
    "    fp = ff[ipeak]\n",
    "    Tp = 1.0 / fp if fp > 0 else np.nan\n",
    "\n",
    "    # Mean period Tm0 = m0 / m1\n",
    "    Tm0 = (m0 / m1) if (m1 > 0) else np.nan\n",
    "\n",
    "    return dict(m0=m0, Hm0=Hm0, fp=fp, Tp=Tp, m1=m1, Tm0=Tm0)\n",
    "\n",
    "\n",
    "def add_period_axis(ax, period_ticks_s=(0.5, 1, 2, 5, 10, 20, 50)):\n",
    "    \"\"\"\n",
    "    Add a top x-axis labeled Period (s) corresponding to bottom frequency axis (Hz).\n",
    "    Works best for log-scaled frequency axes.\n",
    "    \"\"\"\n",
    "    ax_top = ax.twiny()\n",
    "    ax_top.set_xscale(\"log\")\n",
    "\n",
    "    # Match limits in frequency space\n",
    "    fmin, fmax = ax.get_xlim()\n",
    "    ax_top.set_xlim(fmin, fmax)\n",
    "\n",
    "    # Place ticks at frequencies corresponding to selected periods\n",
    "    period_ticks_s = np.asarray(period_ticks_s, dtype=float)\n",
    "    f_ticks = 1.0 / period_ticks_s\n",
    "\n",
    "    # Keep only ticks within current frequency limits\n",
    "    mask = (f_ticks >= fmin) & (f_ticks <= fmax)\n",
    "    ax_top.set_xticks(f_ticks[mask])\n",
    "    ax_top.set_xticklabels([f\"{p:g}\" for p in period_ticks_s[mask]])\n",
    "\n",
    "    ax_top.set_xlabel(\"Period (s)\")\n",
    "    return ax_top\n",
    "\n",
    "    \n",
    "def analyze_experiment(\n",
    "    site_dfs: dict,\n",
    "    color_map: dict,\n",
    "    experiment_name: str,\n",
    "    fs: float = 8.0,\n",
    "    seg_seconds: float = 120.0,\n",
    "    overlap_frac: float = 0.5,\n",
    "    fmin: float = 0.02,\n",
    "    fmax: float = 2.5,\n",
    "    eta_col: str = \"Waves\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute Welch variance spectra, 95% CI, and bulk wave statistics\n",
    "    for one experiment with multiple sites.\n",
    "    \"\"\"\n",
    "\n",
    "    nperseg = int(seg_seconds * fs)\n",
    "    noverlap = int(overlap_frac * nperseg)\n",
    "\n",
    "    spec = {}\n",
    "    stats_rows = []\n",
    "\n",
    "    for site, df in site_dfs.items():\n",
    "\n",
    "        # ---- Minimal conversion: DataFrame → NumPy ----\n",
    "        eta = df[eta_col].to_numpy(dtype=float)\n",
    "        eta = eta[np.isfinite(eta)]   # optional but safe\n",
    "\n",
    "        # ---- Welch variance spectrum ----\n",
    "        f, S = welch(\n",
    "            eta,\n",
    "            fs=fs,\n",
    "            window=\"hann\",\n",
    "            nperseg=nperseg,\n",
    "            noverlap=noverlap,\n",
    "            detrend=\"constant\",\n",
    "            scaling=\"density\",\n",
    "            return_onesided=True\n",
    "        )\n",
    "\n",
    "        # ---- Welch degrees of freedom (approximate) ----\n",
    "        step = nperseg - noverlap\n",
    "        K = 1 + (len(eta) - nperseg) // step\n",
    "        K = int(max(K, 1))\n",
    "        dof = 2 * K\n",
    "\n",
    "        # ---- 95% confidence limits ----\n",
    "        alpha = 0.05\n",
    "        Slo = (dof * S) / chi2.ppf(1 - alpha / 2, dof)\n",
    "        Shi = (dof * S) / chi2.ppf(alpha / 2, dof)\n",
    "\n",
    "        # ---- Bulk stats ----\n",
    "        mask = (f >= fmin) & (f <= fmax)\n",
    "        ff = f[mask]\n",
    "        SS = S[mask]\n",
    "\n",
    "        m0 = np.trapezoid(SS, ff)\n",
    "        m1 = np.trapezoid(ff * SS, ff)\n",
    "\n",
    "        Hm0 = 4 * np.sqrt(m0)\n",
    "        fp = ff[np.argmax(SS)]\n",
    "        Tp = 1 / fp\n",
    "        Tm0 = m0 / m1\n",
    "\n",
    "        spec[site] = dict(f=f, S=S, Slo=Slo, Shi=Shi, dof=dof, K=K)\n",
    "\n",
    "        stats_rows.append({\n",
    "            \"experiment\": experiment_name,\n",
    "            \"site\": site,\n",
    "            \"Hm0 (m)\": Hm0,\n",
    "            \"Tp (s)\": Tp,\n",
    "            \"Tm0 (s)\": Tm0,\n",
    "            \"segments_K\": K,\n",
    "            \"dof\": dof\n",
    "        })\n",
    "\n",
    "    stats_df = pd.DataFrame(stats_rows)\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    for site in site_dfs.keys():   # <-- uses keys in order\n",
    "        print(site)\n",
    "        out = spec[site]\n",
    "        f, S = out[\"f\"], out[\"S\"]\n",
    "        mask = (f >= fmin) & (f <= fmax)\n",
    "    \n",
    "        # ax.loglog(f[mask], S[mask], color=color_map.get(site), label=site)\n",
    "        ax.semilogx(f[mask], S[mask], color=color_map.get(site), label=site)\n",
    "\n",
    "        ax.fill_between(\n",
    "            f[mask],\n",
    "            out[\"Slo\"][mask],\n",
    "            out[\"Shi\"][mask],\n",
    "            alpha=0.25,\n",
    "            linewidth=0,\n",
    "            color=color_map.get(site),\n",
    "        )\n",
    "    \n",
    "    ax.set_xlabel(\"Frequency (Hz)\")\n",
    "    ax.set_ylabel(r\"Variance spectrum $S_{\\eta\\eta}(f)$ (m$^2$/Hz)\")\n",
    "    ax.set_title(\n",
    "        f\"{experiment_name}: Welch variance spectra\\n\"\n",
    "        f\"{seg_seconds:.0f}-s segments, {overlap_frac*100:.0f}% overlap\"\n",
    "    )\n",
    "    ax.grid(True, which=\"both\")\n",
    "    ax.legend()\n",
    "    \n",
    "    # Add top axis in Period (s)\n",
    "    add_period_axis(ax, period_ticks_s=(0.5, 1, 2, 5, 10, 20, 50))\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    return spec, stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a8990e6-9aa7-4f21-beb1-f98666ba1469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read processed data\n",
    "data_dir = \"/Users/sophiafamely/Documents/ScienceFair2526/Data/\"\n",
    "df_blue1r = pd.read_csv( data_dir+\"BlueData.txt\", index_col=0, parse_dates=True )\n",
    "df_red1r = pd.read_csv( data_dir+\"RedData.txt\", index_col=0, parse_dates=True )\n",
    "df_green1r = pd.read_csv( data_dir+\"GreenData.txt\", index_col=0, parse_dates=True )\n",
    "\n",
    "df_yellow2r = pd.read_csv( data_dir+\"YellowData.txt\", index_col=0, parse_dates=True )\n",
    "df_red2r = pd.read_csv( data_dir+\"RedData.txt\", index_col=0, parse_dates=True )\n",
    "df_green2r = pd.read_csv( data_dir+\"GreenData.txt\", index_col=0, parse_dates=True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db919fe2-9f74-4fd7-a57f-aedb6c472a9b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Waves'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fa-env/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'Waves'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m exp1_sites = {\u001b[33m'\u001b[39m\u001b[33mOffshore\u001b[39m\u001b[33m'\u001b[39m: df_blue1r, \u001b[33m'\u001b[39m\u001b[33mRocks\u001b[39m\u001b[33m'\u001b[39m: df_red1r, \u001b[33m'\u001b[39m\u001b[33mGrass\u001b[39m\u001b[33m'\u001b[39m: df_green1r }\n\u001b[32m      3\u001b[39m color_map1  = {\n\u001b[32m      4\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mOffshore\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m,       \u001b[38;5;66;03m# blue\u001b[39;00m\n\u001b[32m      5\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mRocks\u001b[39m\u001b[33m\"\u001b[39m:    \u001b[33m\"\u001b[39m\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m,       \u001b[38;5;66;03m# red\u001b[39;00m\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mGrass\u001b[39m\u001b[33m\"\u001b[39m:    \u001b[33m\"\u001b[39m\u001b[33mg\u001b[39m\u001b[33m\"\u001b[39m,       \u001b[38;5;66;03m# green\u001b[39;00m\n\u001b[32m      7\u001b[39m }\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m spec1, stats1 = \u001b[43manalyze_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp1_sites\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolor_map1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mExperiment 1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mspec keys:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlist\u001b[39m(spec1.keys()))\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mstats rows:\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(stats1))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 142\u001b[39m, in \u001b[36manalyze_experiment\u001b[39m\u001b[34m(site_dfs, color_map, experiment_name, fs, seg_seconds, overlap_frac, fmin, fmax, eta_col)\u001b[39m\n\u001b[32m    137\u001b[39m stats_rows = []\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m site, df \u001b[38;5;129;01min\u001b[39;00m site_dfs.items():\n\u001b[32m    140\u001b[39m \n\u001b[32m    141\u001b[39m     \u001b[38;5;66;03m# ---- Minimal conversion: DataFrame → NumPy ----\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     eta = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43meta_col\u001b[49m\u001b[43m]\u001b[49m.to_numpy(dtype=\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m    143\u001b[39m     eta = eta[np.isfinite(eta)]   \u001b[38;5;66;03m# optional but safe\u001b[39;00m\n\u001b[32m    145\u001b[39m     \u001b[38;5;66;03m# ---- Welch variance spectrum ----\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fa-env/lib/python3.13/site-packages/pandas/core/frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/fa-env/lib/python3.13/site-packages/pandas/core/indexes/base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'Waves'"
     ]
    }
   ],
   "source": [
    "# Process exp. 1\n",
    "exp1_sites = {'Offshore': df_blue1r, 'Rocks': df_red1r, 'Grass': df_green1r }\n",
    "color_map1  = {\n",
    "    \"Offshore\": \"b\",       # blue\n",
    "    \"Rocks\":    \"r\",       # red\n",
    "    \"Grass\":    \"g\",       # green\n",
    "}\n",
    "spec1, stats1 = analyze_experiment(exp1_sites, color_map1, \"Experiment 1\")\n",
    "print(\"spec keys:\", list(spec1.keys()))\n",
    "print(\"stats rows:\", len(stats1))\n",
    "\n",
    "# Process exp. 2\n",
    "exp2_sites = {'Deep': df_red2r, 'Middle': df_yellow2r, 'Shallow': df_green2r }\n",
    "color_map2  = {\n",
    "    \n",
    "    \"Deep\":    \"r\",       # red\n",
    "    \"Middle\":     \"gold\",    # yellow\n",
    "    \"Shallow\":    \"g\",       # green\n",
    "}\n",
    "spec2, stats2 = analyze_experiment(exp2_sites, color_map2, \"Experiment 2 Control\")\n",
    "print(\"spec keys:\", list(spec2.keys()))\n",
    "print(\"stats rows:\", len(stats2))\n",
    "\n",
    "# Combine stats tables if desired:\n",
    "stats_all = pd.concat([stats1, stats2], ignore_index=True)\n",
    "display(stats_all)\n",
    "stats_all.to_csv(\"wave_bulk_stats_welch.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
